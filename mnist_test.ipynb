{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Note: all the following is not quite the scenario these models are being studied for. The purpose is to see how unsupervised models can extract useful features and model probability distribution of given data. RBM can be viewed as a contemporary neural network (though 'double-edged'), so the weights they learn under unsupervised learning procedure can be used to initialize feedforward NN with good prior and then fine-tuned to achieve faster learning with better generalization (as Mr. Hinton initially proposed in 2006's paper)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import MNIST_Dataset.LoadMNIST as mnist\n",
    "\n",
    "from MyRBM.RMB_Classifier import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading MNIST dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "mnist.load('MNIST_Dataset/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "sparse_training_labels = np.zeros((mnist.training_images_count, 10))\n",
    "\n",
    "for i, label in enumerate(mnist.training_labels):\n",
    "    sparse_training_labels[i][int(label)] = 1.0\n",
    "\n",
    "sparse_testing_labels = np.zeros((mnist.test_images_count, 10))\n",
    "\n",
    "for i, label in enumerate(mnist.test_labels):\n",
    "    sparse_testing_labels[i][int(label)] = 1.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_images = mnist.training_images.reshape((mnist.training_images.shape[0], mnist.images_size)) / 255\n",
    "test_images = mnist.test_images.reshape((mnist.test_images.shape[0], mnist.images_size)) / 255"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_accuracy(model: Classifier, data: np.array, labels: np.array):\n",
    "    successes = 0\n",
    "    for x, y in zip(data, labels):\n",
    "        if y == model.class_predict(x):\n",
    "            successes += 1\n",
    "\n",
    "    return successes / data.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RBM with 10 hidden layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initializing the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = Classifier(mnist.images_size, 10, 10, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial test accuracy:  0.101\n"
     ]
    }
   ],
   "source": [
    "# initial accuracy is expected to be around 0.1 for obvious reasons\n",
    "print('Initial test accuracy: ', get_accuracy(model, test_images, mnist.test_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model training.\n",
      "Epochs:  10\n",
      "Batch size:  16\n",
      "Gibb samples:  1\n",
      "Learning rate:  0.1\n",
      "Persistence:  off\n",
      "Momentum:  0.8\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "EPOCH 2...\n",
      "EPOCH 3...\n",
      "EPOCH 4...\n",
      "EPOCH 5...\n",
      "EPOCH 6...\n",
      "EPOCH 7...\n",
      "EPOCH 8...\n",
      "EPOCH 9...\n",
      "EPOCH 10...\n",
      "Done!\n",
      "Test accuracy:  0.6892\n"
     ]
    }
   ],
   "source": [
    "model.fit_classifier(train_images, sparse_training_labels, lr=1e-1)\n",
    "print('Test accuracy: ', get_accuracy(model, test_images, mnist.test_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model training.\n",
      "Epochs:  10\n",
      "Batch size:  64\n",
      "Gibb samples:  5\n",
      "Learning rate:  0.01\n",
      "Persistence:  off\n",
      "Momentum:  0.8\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "EPOCH 2...\n",
      "EPOCH 3...\n",
      "EPOCH 4...\n",
      "EPOCH 5...\n",
      "EPOCH 6...\n",
      "EPOCH 7...\n",
      "EPOCH 8...\n",
      "EPOCH 9...\n",
      "EPOCH 10...\n",
      "Done!\n",
      "Test accuracy:  0.7081\n"
     ]
    }
   ],
   "source": [
    "model.fit_classifier(train_images, sparse_training_labels, lr=1e-2, gibb_samples=5, batch_size=64)\n",
    "print('Test accuracy: ', get_accuracy(model, test_images, mnist.test_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model training.\n",
      "Epochs:  10\n",
      "Batch size:  128\n",
      "Gibb samples:  10\n",
      "Learning rate:  0.001\n",
      "Persistence:  off\n",
      "Momentum:  0.8\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "EPOCH 2...\n",
      "EPOCH 3...\n",
      "EPOCH 4...\n",
      "EPOCH 5...\n",
      "EPOCH 6...\n",
      "EPOCH 7...\n",
      "EPOCH 8...\n",
      "EPOCH 9...\n",
      "EPOCH 10...\n",
      "Done!\n",
      "Test accuracy:  0.7089\n"
     ]
    }
   ],
   "source": [
    "model.fit_classifier(train_images, sparse_training_labels, lr=1e-3, gibb_samples=10, batch_size=128)\n",
    "print('Test accuracy: ', get_accuracy(model, test_images, mnist.test_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In conclusion, with RBM with 10 hidden units we can reach 71% test accuracy in ~30 epochs using standard CD and proper parameters. The model has (28*28+10) * 10 + 28*28+10 + 10 = 8744 parameters. Considering that this classifier is actually based on the unsupervised model — rbm — that performs unsupervised feature detection using energy function and that the gradient of it is intractable and must be approximated the result is quite impressive.\n",
    "\n",
    "Though the implementation supposes binary layers, this particular model showed better result when the input is real-valued and is not turned into binary vectors internally. With such treating and 50 epochs we could get 75% accuracy with pure CD-1 and CD-5 at the end.\n",
    "\n",
    "Using current implementation of PCD (as of 29 dec 2022) did not yield any benefits but quick over-fitting and prolonged learning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RBM with 100 hidden units"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initializing the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model100 = Classifier(mnist.images_size, 10, 100, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial test accuracy:  0.1009\n"
     ]
    }
   ],
   "source": [
    "# initial accuracy is expected to be around 0.1 for obvious reasons\n",
    "print('Initial test accuracy: ', get_accuracy(model100, test_images, mnist.test_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model training.\n",
      "Epochs:  5\n",
      "Batch size:  16\n",
      "Gibb samples:  1\n",
      "Learning rate:  0.01\n",
      "Persistence:  off\n",
      "Momentum:  0.9\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "EPOCH 2...\n",
      "EPOCH 3...\n",
      "EPOCH 4...\n",
      "EPOCH 5...\n",
      "Done!\n",
      "Test accuracy:  0.9166\n"
     ]
    }
   ],
   "source": [
    "model100.fit_classifier(train_images, sparse_training_labels, lr=1e-2, epochs=5, momentum=.9)\n",
    "print('Test accuracy: ', get_accuracy(model100, test_images, mnist.test_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# saving parameters before fumbling with fine-tuning\n",
    "W_copy = model100.W.copy()\n",
    "Bv_copy = model100.Bv.copy()\n",
    "Bh_copy = model100.Bh.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "model100.W = W_copy.copy()\n",
    "model100.Bv = Bv_copy.copy()\n",
    "model100.Bh = Bh_copy.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trying to fine-tune with Persistence Contrastive Divergence (yet not quite beneficial here)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model training.\n",
      "Epochs:  1\n",
      "Batch size:  16\n",
      "Gibb samples:  1\n",
      "Learning rate:  0.0001\n",
      "Persistence:  on\n",
      "Momentum:  0.8\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "Done!\n",
      "Test accuracy:  0.92\n",
      "Running model training.\n",
      "Epochs:  1\n",
      "Batch size:  16\n",
      "Gibb samples:  1\n",
      "Learning rate:  0.0001\n",
      "Persistence:  on\n",
      "Momentum:  0.8\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "Done!\n",
      "Test accuracy:  0.9186\n",
      "Running model training.\n",
      "Epochs:  1\n",
      "Batch size:  16\n",
      "Gibb samples:  1\n",
      "Learning rate:  0.0001\n",
      "Persistence:  on\n",
      "Momentum:  0.8\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "Done!\n",
      "Test accuracy:  0.9186\n",
      "Running model training.\n",
      "Epochs:  1\n",
      "Batch size:  16\n",
      "Gibb samples:  1\n",
      "Learning rate:  0.0001\n",
      "Persistence:  on\n",
      "Momentum:  0.8\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "Done!\n",
      "Test accuracy:  0.9198\n",
      "Running model training.\n",
      "Epochs:  1\n",
      "Batch size:  16\n",
      "Gibb samples:  1\n",
      "Learning rate:  0.0001\n",
      "Persistence:  on\n",
      "Momentum:  0.8\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "Done!\n",
      "Test accuracy:  0.9192\n",
      "Running model training.\n",
      "Epochs:  1\n",
      "Batch size:  16\n",
      "Gibb samples:  1\n",
      "Learning rate:  0.0001\n",
      "Persistence:  on\n",
      "Momentum:  0.8\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "Done!\n",
      "Test accuracy:  0.9213\n",
      "Running model training.\n",
      "Epochs:  1\n",
      "Batch size:  16\n",
      "Gibb samples:  1\n",
      "Learning rate:  0.0001\n",
      "Persistence:  on\n",
      "Momentum:  0.8\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "Done!\n",
      "Test accuracy:  0.9201\n",
      "Running model training.\n",
      "Epochs:  1\n",
      "Batch size:  16\n",
      "Gibb samples:  1\n",
      "Learning rate:  0.0001\n",
      "Persistence:  on\n",
      "Momentum:  0.8\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "Done!\n",
      "Test accuracy:  0.9207\n",
      "Running model training.\n",
      "Epochs:  1\n",
      "Batch size:  16\n",
      "Gibb samples:  1\n",
      "Learning rate:  0.0001\n",
      "Persistence:  on\n",
      "Momentum:  0.8\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "Done!\n",
      "Test accuracy:  0.9204\n",
      "Running model training.\n",
      "Epochs:  1\n",
      "Batch size:  16\n",
      "Gibb samples:  1\n",
      "Learning rate:  0.0001\n",
      "Persistence:  on\n",
      "Momentum:  0.8\n",
      "Weight decay:  1e-06\n",
      "Sample binary:  on\n",
      "\n",
      "EPOCH 1...\n",
      "Done!\n",
      "Test accuracy:  0.9193\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model100.fit_classifier(train_images, sparse_training_labels, lr=1e-4, epochs=1, persistence=True)\n",
    "    print('Test accuracy: ', get_accuracy(model100, test_images, mnist.test_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The base of this caller is an RBM with 100 hidden units has (28*28 + 10) * 100 + (28*28 + 10) + 100 = 80 194 parameters. With 6 epoch it achieves 92% classification accuracy that is probably near its extreme."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
